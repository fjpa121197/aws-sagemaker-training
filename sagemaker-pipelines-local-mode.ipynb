{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker.workflow.pipeline_context import LocalPipelineSession\n",
    "\n",
    "# Create a `LocalPipelineSession` object so that each pipeline step will run locally\n",
    "# To run this pipeline in the cloud, you must change `LocalPipelineSession()` to `PipelineSession()`\n",
    "\n",
    "\n",
    "region = 'eu-west-1'\n",
    "\n",
    "role = None  # Role is set below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_bucket = 'sagemaker-local-pipeline-tutorials'\n",
    "prefix = \"sagemaker-pipelines-local-mode-example-1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = boto3.Session(profile_name='francisco-jupyter-experiment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eu-west-1\n"
     ]
    }
   ],
   "source": [
    "print(region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Windows Support for Local Mode is Experimental\n"
     ]
    }
   ],
   "source": [
    "local_pipeline_session = LocalPipelineSession(boto_session = session, default_bucket = default_bucket)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Couldn't call 'get_role' to get Role ARN from role name fjpa121197 to get Role path.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "   role = sagemaker.get_execution_role()\n",
    "except ValueError:\n",
    "   iam = session.client('iam')\n",
    "   role = iam.get_role(RoleName='AmazonSageMaker-ExecutionRole-20221021T085513')['Role']['Arn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arn:aws:iam::019360497917:role/service-role/AmazonSageMaker-ExecutionRole-20221021T085513\n"
     ]
    }
   ],
   "source": [
    "print(role)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A subdirectory or file data already exists.\n"
     ]
    }
   ],
   "source": [
    "!mkdir data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pull the dataset from SageMaker's public S3 bucket and upload it to your own S3 bucket\n",
    "\n",
    "local_path = r\"data/abalone-dataset.csv\"\n",
    "\n",
    "s3 = session.resource(\"s3\")\n",
    "s3.Bucket(f\"sagemaker-sample-files\").download_file(\n",
    "    \"datasets/tabular/uci_abalone/abalone.csv\", local_path\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_uri = f\"{prefix}/abalone-data-set/abalone-dataset.csv\"\n",
    "\n",
    "# Filename - File to upload\n",
    "# Bucket - Bucket to upload to (the top level directory under AWS S3)\n",
    "# Key - S3 object name (can contain subdirectories). If not specified then file_name is used\n",
    "s3.meta.client.upload_file(Filename=local_path, Bucket=default_bucket, Key=base_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data_uri = \"s3://sagemaker-local-pipeline-tutorials/sagemaker-pipelines-local-mode-example-1/abalone-data-set/abalone-dataset.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.workflow.parameters import ParameterString, ParameterFloat\n",
    "\n",
    "processing_instance_count = 1\n",
    "training_instance_count = 1\n",
    "transform_instance_count = 1\n",
    "instance_type = \"ml.m5.xlarge\"\n",
    "\n",
    "input_data = ParameterString(\n",
    "    name=\"InputData\",\n",
    "    default_value=input_data_uri,\n",
    ")\n",
    "\n",
    "mse_threshold = ParameterFloat(name=\"MseThreshold\", default_value=7.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A subdirectory or file code already exists.\n"
     ]
    }
   ],
   "source": [
    "!mkdir code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting code/preprocessing.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile code/preprocessing.py\n",
    "import argparse\n",
    "import os\n",
    "import requests\n",
    "import tempfile\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "\n",
    "\n",
    "# Since we get a headerless CSV file, we specify the column names here.\n",
    "feature_columns_names = [\n",
    "    \"sex\",\n",
    "    \"length\",\n",
    "    \"diameter\",\n",
    "    \"height\",\n",
    "    \"whole_weight\",\n",
    "    \"shucked_weight\",\n",
    "    \"viscera_weight\",\n",
    "    \"shell_weight\",\n",
    "]\n",
    "label_column = \"rings\"\n",
    "\n",
    "feature_columns_dtype = {\n",
    "    \"sex\": str,\n",
    "    \"length\": np.float64,\n",
    "    \"diameter\": np.float64,\n",
    "    \"height\": np.float64,\n",
    "    \"whole_weight\": np.float64,\n",
    "    \"shucked_weight\": np.float64,\n",
    "    \"viscera_weight\": np.float64,\n",
    "    \"shell_weight\": np.float64,\n",
    "}\n",
    "label_column_dtype = {\"rings\": np.float64}\n",
    "\n",
    "\n",
    "def merge_two_dicts(x, y):\n",
    "    z = x.copy()\n",
    "    z.update(y)\n",
    "    return z\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    base_dir = \"/opt/ml/processing\"\n",
    "\n",
    "    df = pd.read_csv(\n",
    "        f\"{base_dir}/input/abalone-dataset.csv\",\n",
    "        header=None,\n",
    "        names=feature_columns_names + [label_column],\n",
    "        dtype=merge_two_dicts(feature_columns_dtype, label_column_dtype),\n",
    "    )\n",
    "    numeric_features = list(feature_columns_names)\n",
    "    numeric_features.remove(\"sex\")\n",
    "    numeric_transformer = Pipeline(\n",
    "        steps=[\n",
    "            (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "            (\"scaler\", StandardScaler()),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    categorical_features = [\"sex\"]\n",
    "    categorical_transformer = Pipeline(\n",
    "        steps=[\n",
    "            (\"imputer\", SimpleImputer(strategy=\"constant\", fill_value=\"missing\")),\n",
    "            (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\")),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    preprocess = ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"num\", numeric_transformer, numeric_features),\n",
    "            (\"cat\", categorical_transformer, categorical_features),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    y = df.pop(\"rings\")\n",
    "    X_pre = preprocess.fit_transform(df)\n",
    "    y_pre = y.to_numpy().reshape(len(y), 1)\n",
    "\n",
    "    X = np.concatenate((y_pre, X_pre), axis=1)\n",
    "\n",
    "    np.random.shuffle(X)\n",
    "    train, validation, test = np.split(X, [int(0.7 * len(X)), int(0.85 * len(X))])\n",
    "\n",
    "    pd.DataFrame(train).to_csv(f\"{base_dir}/train/train.csv\", header=False, index=False)\n",
    "    pd.DataFrame(validation).to_csv(\n",
    "        f\"{base_dir}/validation/validation.csv\", header=False, index=False\n",
    "    )\n",
    "    pd.DataFrame(test).to_csv(f\"{base_dir}/test/test.csv\", header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.sklearn.processing import SKLearnProcessor\n",
    "\n",
    "framework_version = \"1.0-1\"\n",
    "\n",
    "sklearn_processor = SKLearnProcessor(\n",
    "    framework_version=framework_version,\n",
    "    instance_type=instance_type,\n",
    "    instance_count=processing_instance_count,\n",
    "    base_job_name=\"sklearn-abalone-process\",\n",
    "    role=role,\n",
    "    sagemaker_session=local_pipeline_session,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\francisco.parrilla\\Anaconda3\\envs\\sagemaker-pipeline-tutorial\\lib\\site-packages\\sagemaker\\workflow\\pipeline_context.py:233: UserWarning: Running within a PipelineSession, there will be No Wait, No Logs, and No Job being started.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Job Name:  sklearn-abalone-process-2022-10-25-09-01-51-738\n",
      "Inputs:  [{'InputName': 'input-1', 'AppManaged': False, 'S3Input': {'S3Uri': ParameterString(name='InputData', parameter_type=<ParameterTypeEnum.STRING: 'String'>, default_value='s3://sagemaker-local-pipeline-tutorials/sagemaker-pipelines-local-mode-example-1/abalone-data-set/abalone-dataset.csv'), 'LocalPath': '/opt/ml/processing/input', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}, {'InputName': 'code', 'AppManaged': False, 'S3Input': {'S3Uri': 's3://sagemaker-local-pipeline-tutorials/sklearn-abalone-process-2022-10-25-09-01-51-738/input/code/preprocessing.py', 'LocalPath': '/opt/ml/processing/input/code', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}]\n",
      "Outputs:  [{'OutputName': 'train', 'AppManaged': False, 'S3Output': {'S3Uri': 's3://sagemaker-local-pipeline-tutorials/sklearn-abalone-process-2022-10-25-09-01-51-738/output/train', 'LocalPath': '/opt/ml/processing/train', 'S3UploadMode': 'EndOfJob'}}, {'OutputName': 'validation', 'AppManaged': False, 'S3Output': {'S3Uri': 's3://sagemaker-local-pipeline-tutorials/sklearn-abalone-process-2022-10-25-09-01-51-738/output/validation', 'LocalPath': '/opt/ml/processing/validation', 'S3UploadMode': 'EndOfJob'}}, {'OutputName': 'test', 'AppManaged': False, 'S3Output': {'S3Uri': 's3://sagemaker-local-pipeline-tutorials/sklearn-abalone-process-2022-10-25-09-01-51-738/output/test', 'LocalPath': '/opt/ml/processing/test', 'S3UploadMode': 'EndOfJob'}}]\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.processing import ProcessingInput, ProcessingOutput\n",
    "from sagemaker.workflow.steps import ProcessingStep\n",
    "\n",
    "processor_args = sklearn_processor.run(\n",
    "    inputs=[\n",
    "        ProcessingInput(source=input_data, destination=\"/opt/ml/processing/input\"),\n",
    "    ],\n",
    "    outputs=[\n",
    "        ProcessingOutput(output_name=\"train\", source=\"/opt/ml/processing/train\"),\n",
    "        ProcessingOutput(output_name=\"validation\", source=\"/opt/ml/processing/validation\"),\n",
    "        ProcessingOutput(output_name=\"test\", source=\"/opt/ml/processing/test\"),\n",
    "    ],\n",
    "    code=\"code/preprocessing.py\",\n",
    ")\n",
    "\n",
    "step_process = ProcessingStep(name=\"AbaloneProcess\", step_args=processor_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting code/abalone.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile code/abalone.py\n",
    "\n",
    "import argparse\n",
    "import json\n",
    "import logging\n",
    "import os\n",
    "import pathlib\n",
    "import pickle as pkl\n",
    "import tarfile\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "TRAIN_VALIDATION_FRACTION = 0.2\n",
    "RANDOM_STATE_SAMPLING = 200\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "\n",
    "def prepare_data(train_dir, validation_dir):\n",
    "    \"\"\"Read data from train and validation channel, and return predicting features and target variables.\n",
    "\n",
    "    Args:\n",
    "        data_dir (str): directory which saves the training data.\n",
    "\n",
    "    Returns:\n",
    "        Tuple of training features, training target, validation features, validation target.\n",
    "    \"\"\"\n",
    "    df_train = pd.read_csv(\n",
    "        os.path.join(train_dir, \"train.csv\"),\n",
    "        header=None,\n",
    "    )\n",
    "    df_train = df_train.iloc[np.random.permutation(len(df_train))]\n",
    "    df_train.columns = [\"target\"] + [f\"feature_{x}\" for x in range(df_train.shape[1] - 1)]\n",
    "\n",
    "    try:\n",
    "        df_validation = pd.read_csv(\n",
    "            os.path.join(validation_dir, \"validation.csv\"),\n",
    "            header=None,\n",
    "        )\n",
    "        df_validation.columns = [\"target\"] + [\n",
    "            f\"feature_{x}\" for x in range(df_validation.shape[1] - 1)\n",
    "        ]\n",
    "\n",
    "    except FileNotFoundError:  # when validation data is not available in the directory\n",
    "        logging.info(\n",
    "            f\"Validation data is not found. {TRAIN_VALIDATION_FRACTION * 100}% of training data is \"\n",
    "            f\"randomly selected as validation data. The seed for random sampling is {RANDOM_STATE_SAMPLING}.\"\n",
    "        )\n",
    "        df_validation = df_train.sample(\n",
    "            frac=TRAIN_VALIDATION_FRACTION,\n",
    "            random_state=RANDOM_STATE_SAMPLING,\n",
    "        )\n",
    "        df_train.drop(df_validation.index, inplace=True)\n",
    "        df_validation.reset_index(drop=True, inplace=True)\n",
    "        df_train.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    X_train, y_train = df_train.iloc[:, 1:], df_train.iloc[:, :1]\n",
    "    X_val, y_val = df_validation.iloc[:, 1:], df_validation.iloc[:, :1]\n",
    "\n",
    "    return X_train.values, y_train.values, X_val.values, y_val.values\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"Run training.\"\"\"\n",
    "    parser = argparse.ArgumentParser()\n",
    "\n",
    "    parser.add_argument(\n",
    "        \"--max_depth\",\n",
    "        type=int,\n",
    "    )\n",
    "    parser.add_argument(\"--eta\", type=float)\n",
    "    parser.add_argument(\"--gamma\", type=int)\n",
    "    parser.add_argument(\"--min_child_weight\", type=int)\n",
    "    parser.add_argument(\"--subsample\", type=float)\n",
    "    parser.add_argument(\"--verbosity\", type=int)\n",
    "    parser.add_argument(\"--objective\", type=str)\n",
    "    parser.add_argument(\"--num_round\", type=int)\n",
    "    parser.add_argument(\"--tree_method\", type=str, default=\"auto\")\n",
    "    parser.add_argument(\"--predictor\", type=str, default=\"auto\")\n",
    "    parser.add_argument(\"--learning_rate\", type=str, default=\"auto\")\n",
    "    parser.add_argument(\"--output_data_dir\", type=str, default=os.environ.get(\"SM_OUTPUT_DATA_DIR\"))\n",
    "    parser.add_argument(\"--model_dir\", type=str, default=os.environ.get(\"SM_MODEL_DIR\"))\n",
    "    parser.add_argument(\"--train\", type=str, default=os.environ.get(\"SM_CHANNEL_TRAIN\"))\n",
    "    parser.add_argument(\"--validation\", type=str, default=os.environ.get(\"SM_CHANNEL_VALIDATION\"))\n",
    "    parser.add_argument(\"--sm_hosts\", type=str, default=os.environ.get(\"SM_HOSTS\"))\n",
    "    parser.add_argument(\"--sm_current_host\", type=str, default=os.environ.get(\"SM_CURRENT_HOST\"))\n",
    "\n",
    "    args, _ = parser.parse_known_args()\n",
    "\n",
    "    X_train, y_train, X_val, y_val = prepare_data(args.train, args.validation)\n",
    "\n",
    "    # create dataset for lightgbm\n",
    "    dtrain = xgb.DMatrix(data=X_train, label=y_train)\n",
    "    dval = xgb.DMatrix(data=X_val, label=y_val)\n",
    "    watchlist = [(dtrain, \"train\"), (dval, \"validation\")]\n",
    "\n",
    "    # specify your configurations as a dict\n",
    "    params = {\n",
    "        \"booster\": \"gbtree\",\n",
    "        \"objective\": args.objective,\n",
    "        \"learning_rate\": args.learning_rate,\n",
    "        \"gamma\": args.gamma,\n",
    "        \"min_child_weight\": args.min_child_weight,\n",
    "        \"max_depth\": args.max_depth,\n",
    "        \"subsample\": args.subsample,\n",
    "        \"colsample_bytree\": 1,\n",
    "        \"reg_lambda\": 1,\n",
    "        \"reg_alpha\": 0,\n",
    "        \"eval_metric\": \"rmse\",\n",
    "    }\n",
    "\n",
    "    bst = xgb.train(\n",
    "        params=params,\n",
    "        dtrain=dtrain,\n",
    "        num_boost_round=args.num_round,\n",
    "        evals=watchlist,\n",
    "        xgb_model=None,\n",
    "    )\n",
    "\n",
    "    model_location = args.model_dir + \"/xgboost-model\"\n",
    "    pkl.dump(bst, open(model_location, \"wb\"))\n",
    "    logging.info(\"Stored trained model at {}\".format(model_location))\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.estimator import Estimator\n",
    "from sagemaker.inputs import TrainingInput\n",
    "\n",
    "model_path = f\"s3://{default_bucket}/{prefix}/model\"\n",
    "image_uri = sagemaker.image_uris.retrieve(\n",
    "    framework=\"xgboost\",\n",
    "    region=region,\n",
    "    version=\"1.5-1\",\n",
    "    py_version=\"py3\",\n",
    "    instance_type=instance_type,\n",
    ")\n",
    "\n",
    "xgb_train = Estimator(\n",
    "    image_uri=image_uri,\n",
    "    entry_point=\"code/abalone.py\",\n",
    "    instance_type=instance_type,\n",
    "    instance_count=training_instance_count,\n",
    "    output_path=model_path,\n",
    "    role=role,\n",
    "    sagemaker_session=local_pipeline_session,\n",
    ")\n",
    "\n",
    "xgb_train.set_hyperparameters(\n",
    "    objective=\"reg:squarederror\",\n",
    "    learning_rate=0.01,\n",
    "    num_round=50,\n",
    "    max_depth=5,\n",
    "    eta=0.2,\n",
    "    gamma=4,\n",
    "    min_child_weight=6,\n",
    "    subsample=0.7,\n",
    ")\n",
    "\n",
    "train_args = xgb_train.fit(\n",
    "    inputs={\n",
    "        \"train\": TrainingInput(\n",
    "            s3_data=step_process.properties.ProcessingOutputConfig.Outputs[\"train\"].S3Output.S3Uri,\n",
    "            content_type=\"text/csv\",\n",
    "        ),\n",
    "        \"validation\": TrainingInput(\n",
    "            s3_data=step_process.properties.ProcessingOutputConfig.Outputs[\n",
    "                \"validation\"\n",
    "            ].S3Output.S3Uri,\n",
    "            content_type=\"text/csv\",\n",
    "        ),\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.workflow.steps import TrainingStep\n",
    "\n",
    "step_train = TrainingStep(\n",
    "    name=\"AbaloneTrain\",\n",
    "    step_args=train_args,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing code/evaluation.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile code/evaluation.py\n",
    "import json\n",
    "import pathlib\n",
    "import pickle\n",
    "import tarfile\n",
    "\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost\n",
    "import math\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    model_path = f\"/opt/ml/processing/model/model.tar.gz\"\n",
    "    with tarfile.open(model_path) as tar:\n",
    "        tar.extractall(path=\".\")\n",
    "\n",
    "    model = pickle.load(open(\"xgboost-model\", \"rb\"))\n",
    "\n",
    "    test_path = \"/opt/ml/processing/test/test.csv\"\n",
    "    df = pd.read_csv(test_path, header=None)\n",
    "    df.columns = [\"target\"] + [f\"feature_{x}\" for x in range(df.shape[1] - 1)]\n",
    "\n",
    "    y_test = df.iloc[:, 0].to_numpy()\n",
    "    df.drop(df.columns[0], axis=1, inplace=True)\n",
    "\n",
    "    X_test = xgboost.DMatrix(df.values)\n",
    "\n",
    "    predictions = model.predict(X_test)\n",
    "\n",
    "    mse = mean_squared_error(y_test, predictions)\n",
    "    std = np.std(y_test - predictions)\n",
    "    report_dict = {\n",
    "        \"regression_metrics\": {\n",
    "            \"mse\": {\"value\": math.sqrt(mse), \"standard_deviation\": std},\n",
    "        },\n",
    "    }\n",
    "\n",
    "    output_dir = \"/opt/ml/processing/evaluation\"\n",
    "    pathlib.Path(output_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    evaluation_path = f\"{output_dir}/evaluation.json\"\n",
    "    with open(evaluation_path, \"w\") as f:\n",
    "        f.write(json.dumps(report_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Job Name:  script-abalone-eval-2022-10-25-09-04-44-205\n",
      "Inputs:  [{'InputName': 'input-1', 'AppManaged': False, 'S3Input': {'S3Uri': <sagemaker.workflow.properties.Properties object at 0x000002647A7F1DC0>, 'LocalPath': '/opt/ml/processing/model', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}, {'InputName': 'input-2', 'AppManaged': False, 'S3Input': {'S3Uri': <sagemaker.workflow.properties.Properties object at 0x000002647A11EB80>, 'LocalPath': '/opt/ml/processing/test', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}, {'InputName': 'code', 'AppManaged': False, 'S3Input': {'S3Uri': 's3://sagemaker-local-pipeline-tutorials/script-abalone-eval-2022-10-25-09-04-44-205/input/code/evaluation.py', 'LocalPath': '/opt/ml/processing/input/code', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}]\n",
      "Outputs:  [{'OutputName': 'evaluation', 'AppManaged': False, 'S3Output': {'S3Uri': 's3://sagemaker-local-pipeline-tutorials/script-abalone-eval-2022-10-25-09-04-44-205/output/evaluation', 'LocalPath': '/opt/ml/processing/evaluation', 'S3UploadMode': 'EndOfJob'}}]\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.processing import ScriptProcessor\n",
    "\n",
    "script_eval = ScriptProcessor(\n",
    "    image_uri=image_uri,\n",
    "    command=[\"python3\"],\n",
    "    instance_type=instance_type,\n",
    "    instance_count=processing_instance_count,\n",
    "    base_job_name=\"script-abalone-eval\",\n",
    "    role=role,\n",
    "    sagemaker_session=local_pipeline_session,\n",
    ")\n",
    "\n",
    "eval_args = script_eval.run(\n",
    "    inputs=[\n",
    "        ProcessingInput(\n",
    "            source=step_train.properties.ModelArtifacts.S3ModelArtifacts,\n",
    "            destination=\"/opt/ml/processing/model\",\n",
    "        ),\n",
    "        ProcessingInput(\n",
    "            source=step_process.properties.ProcessingOutputConfig.Outputs[\"test\"].S3Output.S3Uri,\n",
    "            destination=\"/opt/ml/processing/test\",\n",
    "        ),\n",
    "    ],\n",
    "    outputs=[\n",
    "        ProcessingOutput(output_name=\"evaluation\", source=\"/opt/ml/processing/evaluation\"),\n",
    "    ],\n",
    "    code=\"code/evaluation.py\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.workflow.properties import PropertyFile\n",
    "\n",
    "evaluation_report = PropertyFile(\n",
    "    name=\"EvaluationReport\", output_name=\"evaluation\", path=\"evaluation.json\"\n",
    ")\n",
    "step_eval = ProcessingStep(\n",
    "    name=\"AbaloneEval\",\n",
    "    step_args=eval_args,\n",
    "    property_files=[evaluation_report],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.workflow.pipeline import Pipeline\n",
    "\n",
    "pipeline_name = f\"LocalModelPipeline\"\n",
    "pipeline = Pipeline(\n",
    "    name=pipeline_name,\n",
    "    parameters=[\n",
    "        input_data,\n",
    "        mse_threshold,\n",
    "    ],\n",
    "    steps=[step_process, step_train, step_eval],\n",
    "    sagemaker_session=local_pipeline_session,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Version': '2020-12-01',\n",
       " 'Metadata': {},\n",
       " 'Parameters': [{'Name': 'InputData',\n",
       "   'Type': 'String',\n",
       "   'DefaultValue': 's3://sagemaker-local-pipeline-tutorials/sagemaker-pipelines-local-mode-example-1/abalone-data-set/abalone-dataset.csv'},\n",
       "  {'Name': 'MseThreshold', 'Type': 'Float', 'DefaultValue': 7.0}],\n",
       " 'PipelineExperimentConfig': {'ExperimentName': {'Get': 'Execution.PipelineName'},\n",
       "  'TrialName': {'Get': 'Execution.PipelineExecutionId'}},\n",
       " 'Steps': [{'Name': 'AbaloneProcess',\n",
       "   'Type': 'Processing',\n",
       "   'Arguments': {'ProcessingResources': {'ClusterConfig': {'InstanceType': 'ml.m5.xlarge',\n",
       "      'InstanceCount': 1,\n",
       "      'VolumeSizeInGB': 30}},\n",
       "    'AppSpecification': {'ImageUri': '141502667606.dkr.ecr.eu-west-1.amazonaws.com/sagemaker-scikit-learn:1.0-1-cpu-py3',\n",
       "     'ContainerEntrypoint': ['python3',\n",
       "      '/opt/ml/processing/input/code/preprocessing.py']},\n",
       "    'RoleArn': 'arn:aws:iam::019360497917:role/service-role/AmazonSageMaker-ExecutionRole-20221021T085513',\n",
       "    'ProcessingInputs': [{'InputName': 'input-1',\n",
       "      'AppManaged': False,\n",
       "      'S3Input': {'S3Uri': {'Get': 'Parameters.InputData'},\n",
       "       'LocalPath': '/opt/ml/processing/input',\n",
       "       'S3DataType': 'S3Prefix',\n",
       "       'S3InputMode': 'File',\n",
       "       'S3DataDistributionType': 'FullyReplicated',\n",
       "       'S3CompressionType': 'None'}},\n",
       "     {'InputName': 'code',\n",
       "      'AppManaged': False,\n",
       "      'S3Input': {'S3Uri': 's3://sagemaker-local-pipeline-tutorials/sklearn-abalone-process-2022-10-25-09-01-51-738/input/code/preprocessing.py',\n",
       "       'LocalPath': '/opt/ml/processing/input/code',\n",
       "       'S3DataType': 'S3Prefix',\n",
       "       'S3InputMode': 'File',\n",
       "       'S3DataDistributionType': 'FullyReplicated',\n",
       "       'S3CompressionType': 'None'}}],\n",
       "    'ProcessingOutputConfig': {'Outputs': [{'OutputName': 'train',\n",
       "       'AppManaged': False,\n",
       "       'S3Output': {'S3Uri': 's3://sagemaker-local-pipeline-tutorials/sklearn-abalone-process-2022-10-25-09-01-51-738/output/train',\n",
       "        'LocalPath': '/opt/ml/processing/train',\n",
       "        'S3UploadMode': 'EndOfJob'}},\n",
       "      {'OutputName': 'validation',\n",
       "       'AppManaged': False,\n",
       "       'S3Output': {'S3Uri': 's3://sagemaker-local-pipeline-tutorials/sklearn-abalone-process-2022-10-25-09-01-51-738/output/validation',\n",
       "        'LocalPath': '/opt/ml/processing/validation',\n",
       "        'S3UploadMode': 'EndOfJob'}},\n",
       "      {'OutputName': 'test',\n",
       "       'AppManaged': False,\n",
       "       'S3Output': {'S3Uri': 's3://sagemaker-local-pipeline-tutorials/sklearn-abalone-process-2022-10-25-09-01-51-738/output/test',\n",
       "        'LocalPath': '/opt/ml/processing/test',\n",
       "        'S3UploadMode': 'EndOfJob'}}]}}},\n",
       "  {'Name': 'AbaloneTrain',\n",
       "   'Type': 'Training',\n",
       "   'Arguments': {'AlgorithmSpecification': {'TrainingInputMode': 'File',\n",
       "     'TrainingImage': '141502667606.dkr.ecr.eu-west-1.amazonaws.com/sagemaker-xgboost:1.5-1'},\n",
       "    'OutputDataConfig': {'S3OutputPath': 's3://sagemaker-local-pipeline-tutorials/sagemaker-pipelines-local-mode-example-1/model'},\n",
       "    'StoppingCondition': {'MaxRuntimeInSeconds': 86400},\n",
       "    'ResourceConfig': {'VolumeSizeInGB': 30,\n",
       "     'InstanceCount': 1,\n",
       "     'InstanceType': 'ml.m5.xlarge'},\n",
       "    'RoleArn': 'arn:aws:iam::019360497917:role/service-role/AmazonSageMaker-ExecutionRole-20221021T085513',\n",
       "    'InputDataConfig': [{'DataSource': {'S3DataSource': {'S3DataType': 'S3Prefix',\n",
       "        'S3Uri': {'Get': \"Steps.AbaloneProcess.ProcessingOutputConfig.Outputs['train'].S3Output.S3Uri\"},\n",
       "        'S3DataDistributionType': 'FullyReplicated'}},\n",
       "      'ContentType': 'text/csv',\n",
       "      'ChannelName': 'train'},\n",
       "     {'DataSource': {'S3DataSource': {'S3DataType': 'S3Prefix',\n",
       "        'S3Uri': {'Get': \"Steps.AbaloneProcess.ProcessingOutputConfig.Outputs['validation'].S3Output.S3Uri\"},\n",
       "        'S3DataDistributionType': 'FullyReplicated'}},\n",
       "      'ContentType': 'text/csv',\n",
       "      'ChannelName': 'validation'}],\n",
       "    'HyperParameters': {'objective': 'reg:squarederror',\n",
       "     'learning_rate': '0.01',\n",
       "     'num_round': '50',\n",
       "     'max_depth': '5',\n",
       "     'eta': '0.2',\n",
       "     'gamma': '4',\n",
       "     'min_child_weight': '6',\n",
       "     'subsample': '0.7',\n",
       "     'sagemaker_submit_directory': '\"s3://sagemaker-local-pipeline-tutorials/sagemaker-xgboost-2022-10-25-09-02-16-406/source/sourcedir.tar.gz\"',\n",
       "     'sagemaker_program': '\"abalone.py\"',\n",
       "     'sagemaker_container_log_level': '20',\n",
       "     'sagemaker_region': '\"eu-west-1\"'},\n",
       "    'DebugHookConfig': {'S3OutputPath': 's3://sagemaker-local-pipeline-tutorials/sagemaker-pipelines-local-mode-example-1/model',\n",
       "     'CollectionConfigurations': []},\n",
       "    'ProfilerRuleConfigurations': [{'RuleConfigurationName': 'ProfilerReport-1666688537',\n",
       "      'RuleEvaluatorImage': '929884845733.dkr.ecr.eu-west-1.amazonaws.com/sagemaker-debugger-rules:latest',\n",
       "      'RuleParameters': {'rule_to_invoke': 'ProfilerReport'}}],\n",
       "    'ProfilerConfig': {'S3OutputPath': 's3://sagemaker-local-pipeline-tutorials/sagemaker-pipelines-local-mode-example-1/model'}}},\n",
       "  {'Name': 'AbaloneEval',\n",
       "   'Type': 'Processing',\n",
       "   'Arguments': {'ProcessingResources': {'ClusterConfig': {'InstanceType': 'ml.m5.xlarge',\n",
       "      'InstanceCount': 1,\n",
       "      'VolumeSizeInGB': 30}},\n",
       "    'AppSpecification': {'ImageUri': '141502667606.dkr.ecr.eu-west-1.amazonaws.com/sagemaker-xgboost:1.5-1',\n",
       "     'ContainerEntrypoint': ['python3',\n",
       "      '/opt/ml/processing/input/code/evaluation.py']},\n",
       "    'RoleArn': 'arn:aws:iam::019360497917:role/service-role/AmazonSageMaker-ExecutionRole-20221021T085513',\n",
       "    'ProcessingInputs': [{'InputName': 'input-1',\n",
       "      'AppManaged': False,\n",
       "      'S3Input': {'S3Uri': {'Get': 'Steps.AbaloneTrain.ModelArtifacts.S3ModelArtifacts'},\n",
       "       'LocalPath': '/opt/ml/processing/model',\n",
       "       'S3DataType': 'S3Prefix',\n",
       "       'S3InputMode': 'File',\n",
       "       'S3DataDistributionType': 'FullyReplicated',\n",
       "       'S3CompressionType': 'None'}},\n",
       "     {'InputName': 'input-2',\n",
       "      'AppManaged': False,\n",
       "      'S3Input': {'S3Uri': {'Get': \"Steps.AbaloneProcess.ProcessingOutputConfig.Outputs['test'].S3Output.S3Uri\"},\n",
       "       'LocalPath': '/opt/ml/processing/test',\n",
       "       'S3DataType': 'S3Prefix',\n",
       "       'S3InputMode': 'File',\n",
       "       'S3DataDistributionType': 'FullyReplicated',\n",
       "       'S3CompressionType': 'None'}},\n",
       "     {'InputName': 'code',\n",
       "      'AppManaged': False,\n",
       "      'S3Input': {'S3Uri': 's3://sagemaker-local-pipeline-tutorials/script-abalone-eval-2022-10-25-09-04-44-205/input/code/evaluation.py',\n",
       "       'LocalPath': '/opt/ml/processing/input/code',\n",
       "       'S3DataType': 'S3Prefix',\n",
       "       'S3InputMode': 'File',\n",
       "       'S3DataDistributionType': 'FullyReplicated',\n",
       "       'S3CompressionType': 'None'}}],\n",
       "    'ProcessingOutputConfig': {'Outputs': [{'OutputName': 'evaluation',\n",
       "       'AppManaged': False,\n",
       "       'S3Output': {'S3Uri': 's3://sagemaker-local-pipeline-tutorials/script-abalone-eval-2022-10-25-09-04-44-205/output/evaluation',\n",
       "        'LocalPath': '/opt/ml/processing/evaluation',\n",
       "        'S3UploadMode': 'EndOfJob'}}]}},\n",
       "   'PropertyFiles': [{'PropertyFileName': 'EvaluationReport',\n",
       "     'OutputName': 'evaluation',\n",
       "     'FilePath': 'evaluation.json'}]}]}"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "definition = json.loads(pipeline.definition())\n",
    "definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'PipelineArn': 'LocalModelPipeline'}"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.upsert(role_arn=role)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ParameterString(name='InputData', parameter_type=<ParameterTypeEnum.STRING: 'String'>, default_value='s3://sagemaker-local-pipeline-tutorials/sagemaker-pipelines-local-mode-example-1/abalone-data-set/abalone-dataset.csv'), ParameterFloat(name='MseThreshold', parameter_type=<ParameterTypeEnum.FLOAT: 'Float'>, default_value=7.0)]\n",
      "=======================================\n",
      "None\n",
      "Starting execution for pipeline LocalModelPipeline. Execution ID is 1012b92d-36c6-4499-b898-d78d7a2bea8a\n",
      "Starting pipeline step: 'AbaloneProcess'\n",
      "Container 98n77zhl6s-algo-1-1v9iz  Creating\n",
      "Container 98n77zhl6s-algo-1-1v9iz  Created\n",
      "Attaching to 98n77zhl6s-algo-1-1v9iz\n",
      "98n77zhl6s-algo-1-1v9iz exited with code 0\n",
      "Aborting on container exit...\n",
      "Container 98n77zhl6s-algo-1-1v9iz  Stopping\n",
      "Container 98n77zhl6s-algo-1-1v9iz  Stopped\n",
      "===== Job Complete =====\n",
      "Pipeline step 'AbaloneProcess' SUCCEEDED.\n",
      "Starting pipeline step: 'AbaloneTrain'\n",
      "Container war2l2lhcc-algo-1-9wgl1  Creating\n",
      "Container war2l2lhcc-algo-1-9wgl1  Created\n",
      "Attaching to war2l2lhcc-algo-1-9wgl1\n",
      "war2l2lhcc-algo-1-9wgl1  | [2022-10-25 09:06:56.804 b326643b8db7:1 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\n",
      "war2l2lhcc-algo-1-9wgl1  | [2022-10-25:09:06:56:INFO] Imported framework sagemaker_xgboost_container.training\n",
      "war2l2lhcc-algo-1-9wgl1  | [2022-10-25:09:06:56:INFO] Failed to parse hyperparameter objective value reg:squarederror to Json.\n",
      "war2l2lhcc-algo-1-9wgl1  | Returning the value itself\n",
      "war2l2lhcc-algo-1-9wgl1  | [2022-10-25:09:06:56:INFO] No GPUs detected (normal if no gpus installed)\n",
      "war2l2lhcc-algo-1-9wgl1  | [2022-10-25:09:06:56:INFO] Invoking user training script.\n",
      "war2l2lhcc-algo-1-9wgl1  | [2022-10-25:09:06:57:INFO] Module abalone does not provide a setup.py. \n",
      "war2l2lhcc-algo-1-9wgl1  | Generating setup.py\n",
      "war2l2lhcc-algo-1-9wgl1  | [2022-10-25:09:06:57:INFO] Generating setup.cfg\n",
      "war2l2lhcc-algo-1-9wgl1  | [2022-10-25:09:06:57:INFO] Generating MANIFEST.in\n",
      "war2l2lhcc-algo-1-9wgl1  | [2022-10-25:09:06:57:INFO] Installing module with the following command:\n",
      "war2l2lhcc-algo-1-9wgl1  | /miniconda3/bin/python3 -m pip install . \n",
      "war2l2lhcc-algo-1-9wgl1  | Processing /opt/ml/code\n",
      "war2l2lhcc-algo-1-9wgl1  |   Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "war2l2lhcc-algo-1-9wgl1  | \u001b[?25hBuilding wheels for collected packages: abalone\n",
      "war2l2lhcc-algo-1-9wgl1  |   Building wheel for abalone (setup.py) ... \u001b[?25ldone\n",
      "war2l2lhcc-algo-1-9wgl1  | \u001b[?25h  Created wheel for abalone: filename=abalone-1.0.0-py2.py3-none-any.whl size=5628 sha256=cb8b5c503e96474d79a508fcff1279727e2c8a1db03ff11d988599d070d16fd6\n",
      "war2l2lhcc-algo-1-9wgl1  |   Stored in directory: /home/model-server/tmp/pip-ephem-wheel-cache-4pp4dp49/wheels/f3/75/57/158162e9eab7af12b5c338c279b3a81f103b89d74eeb911c00\n",
      "war2l2lhcc-algo-1-9wgl1  | Successfully built abalone\n",
      "war2l2lhcc-algo-1-9wgl1  | Installing collected packages: abalone\n",
      "war2l2lhcc-algo-1-9wgl1  | Successfully installed abalone-1.0.0\n",
      "war2l2lhcc-algo-1-9wgl1  | \u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "war2l2lhcc-algo-1-9wgl1  | \u001b[0m\n",
      "war2l2lhcc-algo-1-9wgl1  | \u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.2.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m22.3\u001b[0m\n",
      "war2l2lhcc-algo-1-9wgl1  | \u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "war2l2lhcc-algo-1-9wgl1  | [2022-10-25:09:07:00:INFO] Failed to parse hyperparameter objective value reg:squarederror to Json.\n",
      "war2l2lhcc-algo-1-9wgl1  | Returning the value itself\n",
      "war2l2lhcc-algo-1-9wgl1  | [2022-10-25:09:07:00:INFO] No GPUs detected (normal if no gpus installed)\n",
      "war2l2lhcc-algo-1-9wgl1  | [2022-10-25:09:07:00:INFO] Invoking user script\n",
      "war2l2lhcc-algo-1-9wgl1  | \n",
      "war2l2lhcc-algo-1-9wgl1  | Training Env:\n",
      "war2l2lhcc-algo-1-9wgl1  | \n",
      "war2l2lhcc-algo-1-9wgl1  | {\n",
      "war2l2lhcc-algo-1-9wgl1  |     \"additional_framework_parameters\": {},\n",
      "war2l2lhcc-algo-1-9wgl1  |     \"channel_input_dirs\": {\n",
      "war2l2lhcc-algo-1-9wgl1  |         \"train\": \"/opt/ml/input/data/train\",\n",
      "war2l2lhcc-algo-1-9wgl1  |         \"validation\": \"/opt/ml/input/data/validation\"\n",
      "war2l2lhcc-algo-1-9wgl1  |     },\n",
      "war2l2lhcc-algo-1-9wgl1  |     \"current_host\": \"algo-1-9wgl1\",\n",
      "war2l2lhcc-algo-1-9wgl1  |     \"framework_module\": \"sagemaker_xgboost_container.training:main\",\n",
      "war2l2lhcc-algo-1-9wgl1  |     \"hosts\": [\n",
      "war2l2lhcc-algo-1-9wgl1  |         \"algo-1-9wgl1\"\n",
      "war2l2lhcc-algo-1-9wgl1  |     ],\n",
      "war2l2lhcc-algo-1-9wgl1  |     \"hyperparameters\": {\n",
      "war2l2lhcc-algo-1-9wgl1  |         \"objective\": \"reg:squarederror\",\n",
      "war2l2lhcc-algo-1-9wgl1  |         \"learning_rate\": 0.01,\n",
      "war2l2lhcc-algo-1-9wgl1  |         \"num_round\": 50,\n",
      "war2l2lhcc-algo-1-9wgl1  |         \"max_depth\": 5,\n",
      "war2l2lhcc-algo-1-9wgl1  |         \"eta\": 0.2,\n",
      "war2l2lhcc-algo-1-9wgl1  |         \"gamma\": 4,\n",
      "war2l2lhcc-algo-1-9wgl1  |         \"min_child_weight\": 6,\n",
      "war2l2lhcc-algo-1-9wgl1  |         \"subsample\": 0.7\n",
      "war2l2lhcc-algo-1-9wgl1  |     },\n",
      "war2l2lhcc-algo-1-9wgl1  |     \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "war2l2lhcc-algo-1-9wgl1  |     \"input_data_config\": {\n",
      "war2l2lhcc-algo-1-9wgl1  |         \"train\": {\n",
      "war2l2lhcc-algo-1-9wgl1  |             \"TrainingInputMode\": \"File\",\n",
      "war2l2lhcc-algo-1-9wgl1  |             \"ContentType\": \"text/csv\"\n",
      "war2l2lhcc-algo-1-9wgl1  |         },\n",
      "war2l2lhcc-algo-1-9wgl1  |         \"validation\": {\n",
      "war2l2lhcc-algo-1-9wgl1  |             \"TrainingInputMode\": \"File\",\n",
      "war2l2lhcc-algo-1-9wgl1  |             \"ContentType\": \"text/csv\"\n",
      "war2l2lhcc-algo-1-9wgl1  |         }\n",
      "war2l2lhcc-algo-1-9wgl1  |     },\n",
      "war2l2lhcc-algo-1-9wgl1  |     \"input_dir\": \"/opt/ml/input\",\n",
      "war2l2lhcc-algo-1-9wgl1  |     \"is_master\": true,\n",
      "war2l2lhcc-algo-1-9wgl1  |     \"job_name\": \"AbaloneTrain-1666688809-7519\",\n",
      "war2l2lhcc-algo-1-9wgl1  |     \"log_level\": 20,\n",
      "war2l2lhcc-algo-1-9wgl1  |     \"master_hostname\": \"algo-1-9wgl1\",\n",
      "war2l2lhcc-algo-1-9wgl1  |     \"model_dir\": \"/opt/ml/model\",\n",
      "war2l2lhcc-algo-1-9wgl1  |     \"module_dir\": \"s3://sagemaker-local-pipeline-tutorials/sagemaker-xgboost-2022-10-25-09-02-16-406/source/sourcedir.tar.gz\",\n",
      "war2l2lhcc-algo-1-9wgl1  |     \"module_name\": \"abalone\",\n",
      "war2l2lhcc-algo-1-9wgl1  |     \"network_interface_name\": \"eth0\",\n",
      "war2l2lhcc-algo-1-9wgl1  |     \"num_cpus\": 8,\n",
      "war2l2lhcc-algo-1-9wgl1  |     \"num_gpus\": 0,\n",
      "war2l2lhcc-algo-1-9wgl1  |     \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "war2l2lhcc-algo-1-9wgl1  |     \"output_dir\": \"/opt/ml/output\",\n",
      "war2l2lhcc-algo-1-9wgl1  |     \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "war2l2lhcc-algo-1-9wgl1  |     \"resource_config\": {\n",
      "war2l2lhcc-algo-1-9wgl1  |         \"current_host\": \"algo-1-9wgl1\",\n",
      "war2l2lhcc-algo-1-9wgl1  |         \"hosts\": [\n",
      "war2l2lhcc-algo-1-9wgl1  |             \"algo-1-9wgl1\"\n",
      "war2l2lhcc-algo-1-9wgl1  |         ]\n",
      "war2l2lhcc-algo-1-9wgl1  |     },\n",
      "war2l2lhcc-algo-1-9wgl1  |     \"user_entry_point\": \"abalone.py\"\n",
      "war2l2lhcc-algo-1-9wgl1  | }\n",
      "war2l2lhcc-algo-1-9wgl1  | \n",
      "war2l2lhcc-algo-1-9wgl1  | Environment variables:\n",
      "war2l2lhcc-algo-1-9wgl1  | \n",
      "war2l2lhcc-algo-1-9wgl1  | SM_HOSTS=[\"algo-1-9wgl1\"]\n",
      "war2l2lhcc-algo-1-9wgl1  | SM_NETWORK_INTERFACE_NAME=eth0\n",
      "war2l2lhcc-algo-1-9wgl1  | SM_HPS={\"eta\":0.2,\"gamma\":4,\"learning_rate\":0.01,\"max_depth\":5,\"min_child_weight\":6,\"num_round\":50,\"objective\":\"reg:squarederror\",\"subsample\":0.7}\n",
      "war2l2lhcc-algo-1-9wgl1  | SM_USER_ENTRY_POINT=abalone.py\n",
      "war2l2lhcc-algo-1-9wgl1  | SM_FRAMEWORK_PARAMS={}\n",
      "war2l2lhcc-algo-1-9wgl1  | SM_RESOURCE_CONFIG={\"current_host\":\"algo-1-9wgl1\",\"hosts\":[\"algo-1-9wgl1\"]}\n",
      "war2l2lhcc-algo-1-9wgl1  | SM_INPUT_DATA_CONFIG={\"train\":{\"ContentType\":\"text/csv\",\"TrainingInputMode\":\"File\"},\"validation\":{\"ContentType\":\"text/csv\",\"TrainingInputMode\":\"File\"}}\n",
      "war2l2lhcc-algo-1-9wgl1  | SM_OUTPUT_DATA_DIR=/opt/ml/output/data\n",
      "war2l2lhcc-algo-1-9wgl1  | SM_CHANNELS=[\"train\",\"validation\"]\n",
      "war2l2lhcc-algo-1-9wgl1  | SM_CURRENT_HOST=algo-1-9wgl1\n",
      "war2l2lhcc-algo-1-9wgl1  | SM_MODULE_NAME=abalone\n",
      "war2l2lhcc-algo-1-9wgl1  | SM_LOG_LEVEL=20\n",
      "war2l2lhcc-algo-1-9wgl1  | SM_FRAMEWORK_MODULE=sagemaker_xgboost_container.training:main\n",
      "war2l2lhcc-algo-1-9wgl1  | SM_INPUT_DIR=/opt/ml/input\n",
      "war2l2lhcc-algo-1-9wgl1  | SM_INPUT_CONFIG_DIR=/opt/ml/input/config\n",
      "war2l2lhcc-algo-1-9wgl1  | SM_OUTPUT_DIR=/opt/ml/output\n",
      "war2l2lhcc-algo-1-9wgl1  | SM_NUM_CPUS=8\n",
      "war2l2lhcc-algo-1-9wgl1  | SM_NUM_GPUS=0\n",
      "war2l2lhcc-algo-1-9wgl1  | SM_MODEL_DIR=/opt/ml/model\n",
      "war2l2lhcc-algo-1-9wgl1  | SM_MODULE_DIR=s3://sagemaker-local-pipeline-tutorials/sagemaker-xgboost-2022-10-25-09-02-16-406/source/sourcedir.tar.gz\n",
      "war2l2lhcc-algo-1-9wgl1  | SM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"train\":\"/opt/ml/input/data/train\",\"validation\":\"/opt/ml/input/data/validation\"},\"current_host\":\"algo-1-9wgl1\",\"framework_module\":\"sagemaker_xgboost_container.training:main\",\"hosts\":[\"algo-1-9wgl1\"],\"hyperparameters\":{\"eta\":0.2,\"gamma\":4,\"learning_rate\":0.01,\"max_depth\":5,\"min_child_weight\":6,\"num_round\":50,\"objective\":\"reg:squarederror\",\"subsample\":0.7},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"train\":{\"ContentType\":\"text/csv\",\"TrainingInputMode\":\"File\"},\"validation\":{\"ContentType\":\"text/csv\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"AbaloneTrain-1666688809-7519\",\"log_level\":20,\"master_hostname\":\"algo-1-9wgl1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-local-pipeline-tutorials/sagemaker-xgboost-2022-10-25-09-02-16-406/source/sourcedir.tar.gz\",\"module_name\":\"abalone\",\"network_interface_name\":\"eth0\",\"num_cpus\":8,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1-9wgl1\",\"hosts\":[\"algo-1-9wgl1\"]},\"user_entry_point\":\"abalone.py\"}\n",
      "war2l2lhcc-algo-1-9wgl1  | SM_USER_ARGS=[\"--eta\",\"0.2\",\"--gamma\",\"4\",\"--learning_rate\",\"0.01\",\"--max_depth\",\"5\",\"--min_child_weight\",\"6\",\"--num_round\",\"50\",\"--objective\",\"reg:squarederror\",\"--subsample\",\"0.7\"]\n",
      "war2l2lhcc-algo-1-9wgl1  | SM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\n",
      "war2l2lhcc-algo-1-9wgl1  | SM_CHANNEL_TRAIN=/opt/ml/input/data/train\n",
      "war2l2lhcc-algo-1-9wgl1  | SM_CHANNEL_VALIDATION=/opt/ml/input/data/validation\n",
      "war2l2lhcc-algo-1-9wgl1  | SM_HP_OBJECTIVE=reg:squarederror\n",
      "war2l2lhcc-algo-1-9wgl1  | SM_HP_LEARNING_RATE=0.01\n",
      "war2l2lhcc-algo-1-9wgl1  | SM_HP_NUM_ROUND=50\n",
      "war2l2lhcc-algo-1-9wgl1  | SM_HP_MAX_DEPTH=5\n",
      "war2l2lhcc-algo-1-9wgl1  | SM_HP_ETA=0.2\n",
      "war2l2lhcc-algo-1-9wgl1  | SM_HP_GAMMA=4\n",
      "war2l2lhcc-algo-1-9wgl1  | SM_HP_MIN_CHILD_WEIGHT=6\n",
      "war2l2lhcc-algo-1-9wgl1  | SM_HP_SUBSAMPLE=0.7\n",
      "war2l2lhcc-algo-1-9wgl1  | PYTHONPATH=/miniconda3/bin:/:/miniconda3/lib/python/site-packages/xgboost/dmlc-core/tracker:/miniconda3/lib/python38.zip:/miniconda3/lib/python3.8:/miniconda3/lib/python3.8/lib-dynload:/miniconda3/lib/python3.8/site-packages\n",
      "war2l2lhcc-algo-1-9wgl1  | \n",
      "war2l2lhcc-algo-1-9wgl1  | Invoking script with the following command:\n",
      "war2l2lhcc-algo-1-9wgl1  | \n",
      "war2l2lhcc-algo-1-9wgl1  | /miniconda3/bin/python3 -m abalone --eta 0.2 --gamma 4 --learning_rate 0.01 --max_depth 5 --min_child_weight 6 --num_round 50 --objective reg:squarederror --subsample 0.7\n",
      "war2l2lhcc-algo-1-9wgl1  | \n",
      "war2l2lhcc-algo-1-9wgl1  | \n",
      "war2l2lhcc-algo-1-9wgl1  | [0]\ttrain-rmse:9.85374\tvalidation-rmse:10.08316\n",
      "war2l2lhcc-algo-1-9wgl1  | [1]\ttrain-rmse:9.76093\tvalidation-rmse:9.98989\n",
      "war2l2lhcc-algo-1-9wgl1  | [2]\ttrain-rmse:9.66923\tvalidation-rmse:9.89894\n",
      "war2l2lhcc-algo-1-9wgl1  | [3]\ttrain-rmse:9.57861\tvalidation-rmse:9.80784\n",
      "war2l2lhcc-algo-1-9wgl1  | [4]\ttrain-rmse:9.48893\tvalidation-rmse:9.71862\n",
      "war2l2lhcc-algo-1-9wgl1  | [5]\ttrain-rmse:9.40063\tvalidation-rmse:9.63030\n",
      "war2l2lhcc-algo-1-9wgl1  | [6]\ttrain-rmse:9.31250\tvalidation-rmse:9.54230\n",
      "war2l2lhcc-algo-1-9wgl1  | [7]\ttrain-rmse:9.22506\tvalidation-rmse:9.45425\n",
      "war2l2lhcc-algo-1-9wgl1  | [8]\ttrain-rmse:9.13855\tvalidation-rmse:9.36846\n",
      "war2l2lhcc-algo-1-9wgl1  | [9]\ttrain-rmse:9.05328\tvalidation-rmse:9.28342\n",
      "war2l2lhcc-algo-1-9wgl1  | [10]\ttrain-rmse:8.96958\tvalidation-rmse:9.19901\n",
      "war2l2lhcc-algo-1-9wgl1  | [11]\ttrain-rmse:8.88616\tvalidation-rmse:9.11509\n",
      "war2l2lhcc-algo-1-9wgl1  | [12]\ttrain-rmse:8.80318\tvalidation-rmse:9.03188\n",
      "war2l2lhcc-algo-1-9wgl1  | [13]\ttrain-rmse:8.72184\tvalidation-rmse:8.94996\n",
      "war2l2lhcc-algo-1-9wgl1  | [14]\ttrain-rmse:8.64030\tvalidation-rmse:8.86808\n",
      "war2l2lhcc-algo-1-9wgl1  | [15]\ttrain-rmse:8.55957\tvalidation-rmse:8.78677\n",
      "war2l2lhcc-algo-1-9wgl1  | [16]\ttrain-rmse:8.47982\tvalidation-rmse:8.70647\n",
      "war2l2lhcc-algo-1-9wgl1  | [17]\ttrain-rmse:8.40144\tvalidation-rmse:8.62846\n",
      "war2l2lhcc-algo-1-9wgl1  | [18]\ttrain-rmse:8.32361\tvalidation-rmse:8.55050\n",
      "war2l2lhcc-algo-1-9wgl1  | [19]\ttrain-rmse:8.24676\tvalidation-rmse:8.47302\n",
      "war2l2lhcc-algo-1-9wgl1  | [20]\ttrain-rmse:8.17045\tvalidation-rmse:8.39534\n",
      "war2l2lhcc-algo-1-9wgl1  | [21]\ttrain-rmse:8.09477\tvalidation-rmse:8.31942\n",
      "war2l2lhcc-algo-1-9wgl1  | [22]\ttrain-rmse:8.02120\tvalidation-rmse:8.24621\n",
      "war2l2lhcc-algo-1-9wgl1  | [23]\ttrain-rmse:7.94749\tvalidation-rmse:8.17298\n",
      "war2l2lhcc-algo-1-9wgl1  | [24]\ttrain-rmse:7.87453\tvalidation-rmse:8.09947\n",
      "war2l2lhcc-algo-1-9wgl1  | [25]\ttrain-rmse:7.80274\tvalidation-rmse:8.02816\n",
      "war2l2lhcc-algo-1-9wgl1  | [26]\ttrain-rmse:7.73161\tvalidation-rmse:7.95730\n",
      "war2l2lhcc-algo-1-9wgl1  | [27]\ttrain-rmse:7.66110\tvalidation-rmse:7.88703\n",
      "war2l2lhcc-algo-1-9wgl1  | [28]\ttrain-rmse:7.59133\tvalidation-rmse:7.81806\n",
      "war2l2lhcc-algo-1-9wgl1  | [29]\ttrain-rmse:7.52237\tvalidation-rmse:7.74920\n",
      "war2l2lhcc-algo-1-9wgl1  | [30]\ttrain-rmse:7.45420\tvalidation-rmse:7.68192\n",
      "war2l2lhcc-algo-1-9wgl1  | [31]\ttrain-rmse:7.38637\tvalidation-rmse:7.61529\n",
      "war2l2lhcc-algo-1-9wgl1  | [32]\ttrain-rmse:7.31898\tvalidation-rmse:7.54806\n",
      "war2l2lhcc-algo-1-9wgl1  | [33]\ttrain-rmse:7.25281\tvalidation-rmse:7.48132\n",
      "war2l2lhcc-algo-1-9wgl1  | [34]\ttrain-rmse:7.18725\tvalidation-rmse:7.41546\n",
      "war2l2lhcc-algo-1-9wgl1  | [35]\ttrain-rmse:7.12238\tvalidation-rmse:7.35116\n",
      "war2l2lhcc-algo-1-9wgl1  | [36]\ttrain-rmse:7.05789\tvalidation-rmse:7.28623\n",
      "war2l2lhcc-algo-1-9wgl1  | [37]\ttrain-rmse:6.99422\tvalidation-rmse:7.22219\n",
      "war2l2lhcc-algo-1-9wgl1  | [38]\ttrain-rmse:6.93126\tvalidation-rmse:7.15921\n",
      "war2l2lhcc-algo-1-9wgl1  | [39]\ttrain-rmse:6.86906\tvalidation-rmse:7.09786\n",
      "war2l2lhcc-algo-1-9wgl1  | [40]\ttrain-rmse:6.80751\tvalidation-rmse:7.03649\n",
      "war2l2lhcc-algo-1-9wgl1  | [41]\ttrain-rmse:6.74688\tvalidation-rmse:6.97712\n",
      "war2l2lhcc-algo-1-9wgl1  | [42]\ttrain-rmse:6.68645\tvalidation-rmse:6.91643\n",
      "war2l2lhcc-algo-1-9wgl1  | [43]\ttrain-rmse:6.62697\tvalidation-rmse:6.85738\n",
      "war2l2lhcc-algo-1-9wgl1  | [44]\ttrain-rmse:6.56830\tvalidation-rmse:6.79905\n",
      "war2l2lhcc-algo-1-9wgl1  | [45]\ttrain-rmse:6.50995\tvalidation-rmse:6.74117\n",
      "war2l2lhcc-algo-1-9wgl1  | [46]\ttrain-rmse:6.45243\tvalidation-rmse:6.68439\n",
      "war2l2lhcc-algo-1-9wgl1  | [47]\ttrain-rmse:6.39562\tvalidation-rmse:6.62806\n",
      "war2l2lhcc-algo-1-9wgl1  | [48]\ttrain-rmse:6.33873\tvalidation-rmse:6.57197\n",
      "war2l2lhcc-algo-1-9wgl1  | [49]\ttrain-rmse:6.28256\tvalidation-rmse:6.51565\n",
      "war2l2lhcc-algo-1-9wgl1  | INFO:root:Stored trained model at /opt/ml/model/xgboost-model\n",
      "war2l2lhcc-algo-1-9wgl1 exited with code 0\n",
      "Aborting on container exit...\n",
      "Container war2l2lhcc-algo-1-9wgl1  Stopping\n",
      "Container war2l2lhcc-algo-1-9wgl1  Stopped\n",
      "===== Job Complete =====\n",
      "Pipeline step 'AbaloneTrain' SUCCEEDED.\n",
      "Starting pipeline step: 'AbaloneEval'\n",
      "Container jhais7c823-algo-1-7ko39  Creating\n",
      "Container jhais7c823-algo-1-7ko39  Created\n",
      "Attaching to jhais7c823-algo-1-7ko39\n",
      "jhais7c823-algo-1-7ko39  | Traceback (most recent call last):\n",
      "jhais7c823-algo-1-7ko39  |   File \"/opt/ml/processing/input/code/evaluation.py\", line 16, in <module>\n",
      "jhais7c823-algo-1-7ko39  |     with tarfile.open(model_path) as tar:\n",
      "jhais7c823-algo-1-7ko39  |   File \"/miniconda3/lib/python3.8/tarfile.py\", line 1603, in open\n",
      "jhais7c823-algo-1-7ko39  |     return func(name, \"r\", fileobj, **kwargs)\n",
      "jhais7c823-algo-1-7ko39  |   File \"/miniconda3/lib/python3.8/tarfile.py\", line 1667, in gzopen\n",
      "jhais7c823-algo-1-7ko39  |     fileobj = GzipFile(name, mode + \"b\", compresslevel, fileobj)\n",
      "jhais7c823-algo-1-7ko39  |   File \"/miniconda3/lib/python3.8/gzip.py\", line 173, in __init__\n",
      "jhais7c823-algo-1-7ko39  |     fileobj = self.myfileobj = builtins.open(filename, mode or 'rb')\n",
      "jhais7c823-algo-1-7ko39  | FileNotFoundError: [Errno 2] No such file or directory: '/opt/ml/processing/model/model.tar.gz'\n",
      "jhais7c823-algo-1-7ko39 exited with code 1\n",
      "Aborting on container exit...\n",
      "Container jhais7c823-algo-1-7ko39  Stopping\n",
      "Container jhais7c823-algo-1-7ko39  Stopped\n",
      "Pipeline step 'AbaloneEval' FAILED. Failure message is: RuntimeError: Failed to run: ['docker-compose', '-f', 'C:\\\\Users\\\\FRANCI~1.PAR\\\\AppData\\\\Local\\\\Temp\\\\tmp188wz79r\\\\docker-compose.yaml', 'up', '--build', '--abort-on-container-exit']\n",
      "Pipeline execution 1012b92d-36c6-4499-b898-d78d7a2bea8a FAILED because step 'AbaloneEval' failed.\n"
     ]
    }
   ],
   "source": [
    "execution = pipeline.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('sagemaker-pipeline-tutorial')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "799c0a76fc9b18cf44eca34e9e11447c0e68e02b7a0534c82ee8670d361abc75"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
